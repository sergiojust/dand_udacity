{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class_vis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "def prettyPicture(clf, X_test, y_test):\n",
    "    x_min = 0.0; x_max = 1.0\n",
    "    y_min = 0.0; y_max = 1.0\n",
    "    \n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    h = .01  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Z is the critical zone that will be painted in the plot\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    %matplotlib inline\n",
    "    print(Z.shape)\n",
    "    print(xx.shape)\n",
    "    # Z is being reshaped to 2-D\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Choose limits for the plot\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    \n",
    "    \n",
    "    # Definimos el color del fondo\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)\n",
    "\n",
    "    # Plot also the test points\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    plt.scatter(grade_sig, bumpy_sig, color = \"b\", label=\"fast\")\n",
    "    plt.scatter(grade_bkg, bumpy_bkg, color = \"r\", label=\"slow\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"bumpiness\")\n",
    "    plt.ylabel(\"grade\")\n",
    "\n",
    "    plt.savefig(\"test.png\")\n",
    "\n",
    "### import base64\n",
    "### import json\n",
    "### import subprocess\n",
    "\n",
    "### def output_image(name, format, bytes):\n",
    "###    image_start = \"BEGIN_IMAGE_f9825uweof8jw9fj4r8\"\n",
    "###    image_end = \"END_IMAGE_0238jfw08fjsiufhw8frs\"\n",
    "###    data = {}\n",
    "###    data['name'] = name\n",
    "###    data['format'] = format\n",
    "###    data['bytes'] = base64.encodestring(bytes)\n",
    "###    print(image_start+json.dumps(data)+image_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep_terrain_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import random\n",
    "\n",
    "\n",
    "def makeTerrainData(n_points=1000):\n",
    "###############################################################################\n",
    "### make the toy dataset\n",
    "    ### Choose one seed so the random scenario its always the same random scenario\n",
    "    random.seed(42)\n",
    "    ### Use random.random() in order to generate 1000 (n_points) numbers between 0 and 1 ((features or input))\n",
    "    grade = [random.random() for ii in range(0,n_points)]\n",
    "    bumpy = [random.random() for ii in range(0,n_points)]\n",
    "    error = [random.random() for ii in range(0,n_points)]\n",
    "    \n",
    "    ### Create a len = 1000 vector that relates grade and bumpy ((labels or output))\n",
    "    y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\n",
    "    \n",
    "    ### Round some high values to 1 so all items are between 0 and 1\n",
    "    for ii in range(0, len(y)):\n",
    "        if grade[ii]>0.8 or bumpy[ii]>0.8:\n",
    "            y[ii] = 1.0\n",
    "\n",
    "### split into train/test sets\n",
    "    ### Create a variable with one measure of grade and one of bumpy\n",
    "    X = [[gg, ss] for gg, ss in zip(grade, bumpy)]\n",
    "\n",
    "    \n",
    "    ### Create a mark at 75% of n_points in order to train the model with 75% of\n",
    "    ### the dataset and test with the other 25%\n",
    "    split = int(0.75*n_points)\n",
    "    X_train = X[0:split]\n",
    "    X_test  = X[split:]\n",
    "    y_train = y[0:split]\n",
    "    y_test  = y[split:]\n",
    "\n",
    "    grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "    bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "\n",
    "    training_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "\n",
    "\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    test_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassifyNB.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(features_train, labels_train):   \n",
    "    ### import the sklearn module for GaussianNB\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "    ### create classifier\n",
    "    clf = GaussianNB()\n",
    "\n",
    "    ### fit the classifier on the training features and labels\n",
    "    clf.fit(features_train, labels_train)\n",
    "\n",
    "    ### return the fit classifier\n",
    "    return clf    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## studentMain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(100, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2115a33b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Complete the code in ClassifyNB.py with the sklearn\n",
    "    Naive Bayes classifier to classify the terrain data.\n",
    "    \n",
    "    The objective of this exercise is to recreate the decision \n",
    "    boundary found in the lesson video, and make a plot that\n",
    "    visually shows the decision boundary \"\"\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\" points mixed\n",
    "### in together--separate them so we can give them different colors in the scatterplot,\n",
    "### and visually identify them\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "\n",
    "# You will need to complete this function imported from the ClassifyNB script.\n",
    "# Be sure to change to that code tab to complete this quiz.\n",
    "clf = classify(features_train, labels_train)\n",
    "\n",
    "\n",
    "### draw the decision boundary with the text points overlaid\n",
    "prettyPicture(clf, features_test, labels_test)\n",
    "#output_image(\"test.png\", \"png\", open(\"test.png\", \"rb\").read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Naive-Bayes Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.896\n"
     ]
    }
   ],
   "source": [
    "def NBAccuracy(features_train, labels_train, features_test, labels_test):\n",
    "    \"\"\" compute the accuracy of your Naive Bayes classifier \"\"\"\n",
    "    ### import the sklearn module for GaussianNB\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    ### create classifier\n",
    "    clf = GaussianNB()\n",
    "\n",
    "    ### fit the classifier on the training features and labels\n",
    "    clf.fit(features_train, labels_train)\n",
    "\n",
    "    ### use the trained classifier to predict labels for the test features\n",
    "    pred = clf.fit(features_test, labels_test)\n",
    "\n",
    "\n",
    "    ### calculate and return the accuracy on the test data\n",
    "    ### this is slightly different than the example, \n",
    "    ### where we just print the accuracy\n",
    "    ### you might need to import an sklearn module\n",
    "    \n",
    "    ### use the trained classifier to predict labels for the test features\n",
    "    \n",
    "    # method 1: It calculates the accuracy w/o the need of running the prediction\n",
    "    accuracy = clf.score(features_test, labels_test)\n",
    "    \n",
    "    # method 2\n",
    "    # It returns a prediction of the labels corresponding to features_test\n",
    "    pred = clf.predict(features_test)\n",
    "    \n",
    "    # It compares the above prediction with the labels_test vector\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "accuracy = NBAccuracy(features_train, labels_train, features_test, labels_test)\n",
    "print(\"Accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896\n"
     ]
    }
   ],
   "source": [
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "def submitAccuracy():\n",
    "    accuracy = NBAccuracy(features_train, labels_train, features_test, labels_test)\n",
    "    return accuracy\n",
    "\n",
    "print(submitAccuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for nltk\n",
      "checking for numpy\n",
      "checking for scipy\n",
      "checking for sklearn\n",
      "downloading the Enron dataset (this may take a while)\n",
      "to check on progress, you can cd up one level, then execute <ls -lthr>\n",
      "Enron dataset should be last item on the list, along with its current size\n",
      "download will complete at about 423 MB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "urlopen() got an unexpected keyword argument 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-37e360941e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../enron_mail_20150507.tar.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"download complete!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: urlopen() got an unexpected keyword argument 'filename'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "print\n",
    "print( \"checking for nltk\")\n",
    "try:\n",
    "    import nltk\n",
    "except ImportError:\n",
    "    print( \"you should install nltk before continuing\")\n",
    "\n",
    "print( \"checking for numpy\")\n",
    "try:\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    print( \"you should install numpy before continuing\")\n",
    "\n",
    "print(\"checking for scipy\")\n",
    "try:\n",
    "    import scipy\n",
    "except:\n",
    "    print( \"you should install scipy before continuing\")\n",
    "\n",
    "print( \"checking for sklearn\")\n",
    "try:\n",
    "    import sklearn\n",
    "except:\n",
    "    print( \"you should install sklearn before continuing\")\n",
    "\n",
    "print\n",
    "print( \"downloading the Enron dataset (this may take a while)\")\n",
    "print( \"to check on progress, you can cd up one level, then execute <ls -lthr>\")\n",
    "print( \"Enron dataset should be last item on the list, along with its current size\")\n",
    "print(\"download will complete at about 423 MB\")\n",
    "import urllib\n",
    "url = \"https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz\"\n",
    "urllib.request.urlopen(url, filename=\"../enron_mail_20150507.tar.gz\") \n",
    "print(\"download complete!\")\n",
    "\n",
    "\n",
    "print\n",
    "print( \"unzipping Enron dataset (this may take a while)\")\n",
    "import tarfile\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "tfile = tarfile.open(\"enron_mail_20150507.tar.gz\", \"r:gz\")\n",
    "tfile.extractall(\".\")\n",
    "\n",
    "print(\"you're ready to go!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-23-15242fb2a7e7>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-15242fb2a7e7>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    def preprocess(words_file = \"C:\\Users\\Serg\\Documents\\Aprendiendo\\Data Analysis\\Module 6 - Machine Learning\\ud120-projects-master\\tools\\word_data.pkl\", authors_file=\"C:\\Users\\Serg\\Documents\\Aprendiendo\\Data Analysis\\Module 6 - Machine Learning\\ud120-projects-master\\tools\\email_authors.pkl\"):\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cPickle\n",
    "import numpy\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(words_file = \"C:\\Users\\Serg\\Documents\\Aprendiendo\\Data Analysis\\Module 6 - Machine Learning\\ud120-projects-master\\tools\\word_data.pkl\", authors_file=\"C:\\Users\\Serg\\Documents\\Aprendiendo\\Data Analysis\\Module 6 - Machine Learning\\ud120-projects-master\\tools\\email_authors.pkl\"):\n",
    "    \"\"\" \n",
    "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
    "        and the corresponding authors (by default email_authors.pkl) and performs\n",
    "        a number of preprocessing steps:\n",
    "            -- splits into training/testing sets (10% testing)\n",
    "            -- vectorizes into tfidf matrix\n",
    "            -- selects/keeps most helpful features\n",
    "\n",
    "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### the words (features) and authors (labels), already largely preprocessed\n",
    "    ### this preprocessing will be repeated in the text learning mini-project\n",
    "    authors_file_handler = open(authors_file, \"r\")\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "\n",
    "    words_file_handler = open(words_file, \"r\")\n",
    "    word_data = cPickle.load(words_file_handler)\n",
    "    words_file_handler.close()\n",
    "\n",
    "    ### test_size is the percentage of events assigned to the test set\n",
    "    ### (remainder go into training)\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    ### text vectorization--go from strings to lists of numbers\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    features_test_transformed  = vectorizer.transform(features_test)\n",
    "\n",
    "\n",
    "\n",
    "    ### feature selection, because text is super high dimensional and \n",
    "    ### can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=10)\n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "\n",
    "    ### info on the data\n",
    "    print( \"no. of Chris training emails:\", sum(labels_train))\n",
    "    print( \"no. of Sara training emails:\", len(labels_train)-sum(labels_train))\n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'email_preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4465bc56e09b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../tools/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0memail_preprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'email_preprocess'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 1 (Naive Bayes) mini-project. \n",
    "\n",
    "    Use a Naive Bayes Classifier to identify emails by their authors\n",
    "    \n",
    "    authors and labels:\n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# the classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"\\ntraining time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# predict\n",
    "t0 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"predicting time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "accuracy = accuracy_score(pred, labels_test)\n",
    "\n",
    "print('\\naccuracy = {0}'.format(accuracy))\n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
